{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copia de Copy of 3. Hibridación Algoritmos Meméticos y Optimización Multiobjetivo.ipynb","version":"0.3.2","provenance":[{"file_id":"1Ej370mxHq_aziG-Qjmrjiz7CsbyH_aF3","timestamp":1558780227654}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HTcEp61EYACS","colab_type":"text"},"source":["# Optimización multi-objetivo\n","Hasta ahora nos hemos enfrentado a problemas de optimización en los que el objetivo era optimizar cierta función, pero dicho objetivo era único:\n","\n","- Maximizar el valor de los objetos que se incluyen en la mochila\n","- Minimizar el número de reinas que se amenazan en el _problema de las n-reinas_\n","- Minimizar la distancia recorrida en el _problema del viajante de comercio_\n","- Maximizar el número de 1's en un array binario en el _problema MaxOnes_\n","\n","Para resolverlos usando un algoritmo evolutivo, hay que definir la codificación de las soluciones, elegir los operadores que se van a utilizar para generar nuevas, y establecer cuál va a ser la función de fitness que guíe al algoritmo en la búsqueda de mejores soluciones. Sin embargo, hay problemas que requieren de un enfoque multi-objetivo porque el problema al que nos enfrentamos consta de varios objetivos de optimización. En este caso, la principal diferencia es que la función de _fitness_ que decidamos utilizar ya no nos devuelve un único valor real, sino que nos devolverá varios, dependiendo del número de objetivos que formen el problema de optimización a resolver:\n","\n","$$\n","f:\\mathbb{S} \\rightarrow \\mathbb{R}^n\n","$$\n","\n","Este pequeño cambio solo afecta a una parte concreta de los algoritmos evolutivos: **los mecanismos de selección**. Como ya hemos visto en temas anteriores, los algoritmos evolutivos basan su funcionamiento, entre otras cosas, en el mecanismo de selección que usan tanto para elegir a las soluciones que sirven de semilla para generar otras nuevas como al mecanismo para determinar qué soluciones de la población sobreviven y pasan a la siguiente generación del proceso evolutivo.\n","\n","Por tanto, la diferencia entre enfrentarse a un problema multi-objetivo con respecto a uno con objetivo único radica, precisamente, en los mecanismos de selección que se utilicen, básicamente porque son éstos los que tienen en cuenta el _fitness_ de los individuos y, realmente, es el único cambio entre ambos enfoques.\n","\n","A lo largo de la historia de los algoritmos evolutivos se han ido diseñando diferentes enfoques multi-objetivo. Más adelante se describen dos de los más usados: NSGA-II y SPEA2. Pero antes, veamos qué es la **dominancia** en espacios multi-dimensionales y qué se conoce como el **frente de Pareto**.\n"]},{"cell_type":"markdown","metadata":{"id":"JYYuTD8Oe88D","colab_type":"text"},"source":["## Dominancia en espacios multi-dimensionales y frentes de Pareto\n","Formalmente, un **problema de optimización multi-objetivo** se define como maximizar/minimizar:\n","\n","$$\n","f(x)=(f_1(x),f_2(x),\\ldots,f_k(x))\n","$$\n","\n","Para establecer un orden de calidad en las soluciones de un espacio multi-dimensiona, se define lo que se conoce como dominancia. Se dice que un vector $\\overrightarrow{u}$ domina a otro $\\overrightarrow{v}$, denotándose $\\overrightarrow{u}\\preceq \\overrightarrow{v}$,  sí y solo sí (suponiendo maximización):\n","\n","$$\n","{\\Large \\forall}i\\in\\left\\{1, 2, \\ldots, k \\right\\}\\mid f_i(\\overrightarrow{u}) \\geq f_i(\\overrightarrow{v}) \\wedge \\exists j \\in \\left\\{1, 2, \\ldots, k \\right\\} \\mid f_j(\\overrightarrow{u}) > f_j(\\overrightarrow{v})\n","$$\n","\n","Es decir, **una solución domina a otra si es mejor o igual en todos los objetivos y al menos mejor en uno de ellos**. Por ejemplo, en la siguiente figura, si suponemos que hay que maximizar ambos objetivos, tanto $u$ como $v$ dominan a $w$, sin embargo las dos primeras no son dominadas por ninguna otra solución.\n","\n","![Dominancia](https://www.researchgate.net/profile/Jamal_Toutouh/publication/323005390/figure/fig7/AS:591681388830721@1518079244305/Dominance-in-multi-objective-optimization.png)\n","\n","Una solución que no está dominada por ninguna otra se conoce como **solución Pareto-óptima**. El conjunto de todas las soluciones no dominadas $X^*\\subset X$ es el **conjunto Pareto-óptimo** y forman la solución óptima del problema multiobjetivo. Por su parte, los valores de _fitness_ de las soluciones del dicho conjunto forman lo que se conoce como **Frente de Pareto**.\n","\n","Debido a que no suele existir una única solución optima, sino que existe un conjunto (a veces infinito) de soluciones No-Dominadas que forman la Frontera de Pareto, el objetivo de la optimización multi-objetivo es encontrar una aproximación del frente de Pareto de la mayor calidad posible.\n","\n","A continuación se presenta uno de los algoritmos evolutivos multi-objetivo más conocidos y utilizados: el **NSGA-II**."]},{"cell_type":"markdown","metadata":{"id":"FAoBMO5AdC0G","colab_type":"text"},"source":["## Non-dominated Sorting Genetic Algorithm II (NSGA-II)\n","El algoritmo **NSGA-II** pertenece a la familia de los algoritmos evolutivos y sus características principales se resumen en:\n","\n","1. Usa un enfoque elitista. Es decir, las mejores soluciones pasan automáticamente a la siguiente generación\n","2. Utiliza un mecanismo explícito para conservar la diversidad de la población. Se le conoce como **crowding distance**.\n","3. Basa su selección en las soluciones no dominadas\n","\n","Su modo de funcionamiento es el siguiente:\n","\n","1. Se hace una ordenación de las soluciones padre e hijas en base a su no-dominancia. De esta forma se agrupan en varios conjuntos: soluciones no-dominadas, soluciones dominadas por una solución, por dos soluciones, etc.\n","2. Se completa la nueva población añadiendo las soluciones a partir de los conjuntos calculados anteriormente.\n","3. Si un conjunto no se puede añadir completamente, se reordenan las soluciones que forman parte de dicho conjunto mediante la métrica **crowding-distance**, y se seleccionan tantos como individuos falten para completar la próxima población.\n","4. Crea una población de descendientes a partir de esta nueva población utilizando una selección por torneo (se comparan primero por el número de soluciones que las dominan y, si es igual, se compara por sus distancias de _crowding_), operadores de cruce y de mutación.\n","\n","![NSGA-II](https://pythonhealthcaremodelling.files.wordpress.com/2019/01/nsga.png)\n","\n","Para ver cómo funciona el algoritmo y resolver algunos problemas vamos a utilizar una librería de optimización multiobjetivo para Python, denominada [Platypus](https://platypus.readthedocs.io/en/latest/#). Esta librería trae algunas funciones de elevada complejidad de optimización que suelen usarse como benchmarks para los algoritmos de optimización multiobjetivo. En el siguiente ejemplo se optimizará la función conocida como [DTLZ2](https://sop.tik.ee.ethz.ch/download/supplementary/testproblems/dtlz2/index.php):"]},{"cell_type":"code","metadata":{"id":"Ti0UAj54temf","colab_type":"code","colab":{}},"source":["# Instalación de la librería en el entorno de ejecución de la notebook\n","!pip install platypus-opt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Fx3WjJFt-un","colab_type":"code","colab":{}},"source":["from platypus import NSGAII, DTLZ2\n","\n","# definición del problema\n","problem = DTLZ2()\n","\n","# se instancia el algoritmo a resolver\n","algorithm = NSGAII(problem)\n","\n","# se lanza el algoritmo especificando el número máximo de evaluaciones\n","algorithm.run(10000)\n","\n","# plot the results using matplotlib\n","import matplotlib.pyplot as plt\n","\n","plt.scatter([s.objectives[0] for s in algorithm.result],\n","            [s.objectives[1] for s in algorithm.result])\n","plt.xlim([0, 1.1])\n","plt.ylim([0, 1.1])\n","plt.xlabel(\"$f_1(x)$\")\n","plt.ylabel(\"$f_2(x)$\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kV5ZZ93lIZby","colab_type":"text"},"source":["Vamos a usar la misma librería para resolver el problema de la mochila ilimitada y multi-objetivo:"]},{"cell_type":"code","metadata":{"id":"wHO029fUxU9r","colab_type":"code","colab":{}},"source":["import random\n","\n","from platypus import Problem, Integer, NSGAII\n","import matplotlib.pyplot as plt\n","\n","\n","class MochilaMulti(Problem):\n","    def __init__(self, pesos, valores, volumenes, W):\n","        super(MochilaMulti, self).__init__(nvars=len(valores), nobjs=2, nconstrs=1)\n","        self.types[:] = [Integer(0, W // min(pesos))] * len(valores)\n","        self.constraints[:] = \">=0\"\n","        self.directions[:] = [Problem.MAXIMIZE, Problem.MINIMIZE]\n","        self.valores = valores\n","        self.volumenes = volumenes\n","        self.W = W\n","        self.pesos = pesos\n","\n","    def evaluate(self, solution):\n","        seleccion = solution.variables\n","        solution.objectives[:] = [sum(list(map(lambda x: x[0]*x[1], zip(seleccion, self.valores)))),\n","                                  sum(list(map(lambda x: x[0]*x[1], zip(seleccion, self.volumenes))))]\n","        solution.constraints[:] = [sum(list(map(lambda x: x[0]*x[1], zip(seleccion, self.pesos)))) - self.W]\n","\n","\n","# Instancia aleatoria del problema\n","N = 60\n","wi = tuple([random.randint(1, 100) for _ in range(N)])\n","vi = tuple([random.randint(1, 100) for _ in range(N)])\n","voli = tuple([random.randint(1, 100) for _ in range(N)])\n","W = sum(wi) // 2\n","\n","problema = MochilaMulti(wi, vi, voli, W)\n","algorithm = NSGAII(problema, population_size=100)\n","algorithm.run(10000)\n","\n","plt.scatter([s.objectives[0] for s in algorithm.result],\n","            [s.objectives[1] for s in algorithm.result])\n","plt.xlabel(\"valor\")\n","plt.ylabel(\"volumen\")\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EOYzk6aQhvvw","colab_type":"text"},"source":["Para terminar con este tema, a continuación se realiza una comparativa de los conjuntos de soluciones no dominadas obtenidas tanto por el algoritmo que acabamos de ver, **NSGA-II**, como con otro algoritmo de optimización multi-objetivo **SPEA2**:"]},{"cell_type":"code","metadata":{"id":"1Tcr55Hgisoh","colab_type":"code","colab":{}},"source":["from platypus import *\n","\n","algoritmos = [NSGAII, SPEA2]\n","problemas = [MochilaMulti(wi, vi, voli, W)]\n","\n","with ProcessPoolEvaluator() as evaluator:\n","        results = experiment(algoritmos, problemas, seeds=1, nfe=10000, evaluator=evaluator)\n","\n","fig = plt.figure(figsize=(45, 16))\n","\n","for i, algorithm in enumerate(six.iterkeys(results)):\n","        result = results[algorithm][\"MochilaMulti\"][0]\n","        \n","        ax = fig.add_subplot(2, 5, i+1)\n","        ax.scatter([s.objectives[0] for s in result],\n","                   [s.objectives[1] for s in result])\n","        ax.set_title(algorithm)\n","        plt.xlabel('valor')\n","        plt.ylabel('volumen')\n","    \n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vVNYZiS1I-nf","colab_type":"text"},"source":["# Hibridación con otros algoritmos: Algoritmos Meméticos\n","Muchos problemas complejos se pueden descomponer en varias partes, entre las cuales habrá algunas partes para las que se conozcan algoritmos de optimización exactos o buenas heurísticas para resolverlas. En estos casos parece que tiene sentido usar una combinación de los métodos más adecuados para los distintos sub-problemas.\n","\n","En general, no existen métodos resolutores de problemas generales exitosos y eficientes. El creciente número de pruebas empíricas y algunos resultados teóricos, como el teorema de [No Free Lunch (NFL)](https://en.wikipedia.org/wiki/No_free_lunch_in_search_and_optimization), respaldan firmemente este punto de vista. Desde el punto de vista de la computación evolutiva, esto implica que los EAs no exhiben el desempeño sugerido en la década de 1980. En otras palabras, un algoritmo evolutivo particular puede ser muy bueno resolviendo un determinado problema, pero no será capaz de superar a una búsqueda aleatoria en la totalidad de tipos de problemas.\n","\n","![No Free Lunch](https://cdn-images-1.medium.com/max/800/1*0QP3OeK7BAOWGlUcDG6VSw.png)\n","\n","En la práctica, aplicamos con frecuencia un algoritmo evolutivo a un problema en el que hay una cantidad considerable de experiencia de usuario y conocimientos adquiridos con esfuerzo. En tales casos, la utilización de esta información en forma de operadores especializados o de buenas soluciones puede resultar beneficiosa para el rendimiento, siempre que se tenga cuidado de no sesgar demasiado la búsqueda en detrimento de la generación de nuevas soluciones. En estos casos, se suele experimentar que la combinación de un método evolutivo y un método heurístico -un algoritmo evolutivo híbrido- funciona mejor que cualquiera de sus algoritmos \"parentales\" por sí solos.\n","\n","Hay varias formas de incorporar conocimiento específico del problema a un algoritmo evolutivo. A continuación veremos algunas de ellas."]},{"cell_type":"markdown","metadata":{"id":"tOMhJqjkNL1A","colab_type":"text"},"source":["## Inicialización 'inteligente' o heurística\n","Una de las formas más obvias de incoporar conocimiento específico del problema es en la fase de inicialización del algoritmo evolutivo. Como hemos visto, la creación de la población inicial de soluciones en un AE es un proceso aleatorio. Sin embargo, introduciendo algunas soluciones conocidas del problema dentro de la población inicial del algoritmo podemos obtener algunas ventajas:\n","\n","1. Es posible evitar 'reinventar la rueda' utilizando soluciones conocidas. De esta forma evitamos que el algoritmo tenga que evolucionar las soluciones iniciales hacia ellas.\n","2.  Una población inicial no aleatoria puede dirigir la búsqueda hacia zonas del espacio de soluciones prometedoras.\n","3. Como siempre, hay que encontrar el equilibrio entre una población totalmente aleatoria y una formada por soluciones conocidas. Como ya hemos comentado, es muy importante mantener la diversidad en los individuos explorados para evitar que el proceso de búsqueda se estanque en un óptimo global\n","\n","Para cambiar la función de inicialización e incluir conocimiento específico del problema en la población, podemos utlizar técnicas como las siguientes:\n","\n","- Sembrar la población con una o más buenas soluciones previamente conocidas, que surjan de otras técnicas. Estas técnicas abarcan desde el ensayo y error humano hasta el uso de heurísticas  _greedy_ altamente especializadas que utilizan información específica de cada caso.\n","- En la inicialización selectiva se crea un gran número de soluciones aleatorias y luego se selecciona la población inicial de entre ellas. Otras alternativas incluyen la selección de un conjunto basado no sólo en lel _fitness_ sino también en la diversidad para maximizar la cobertura del espacio de búsqueda.\n","- Realizar una búsqueda local a partir de cada miembro de la población inicial, de modo que la población inicial consista en un conjunto de puntos que sean localmente óptimos con respecto a algún operador de movimientos.\n","- Usando uno o más de los métodos anteriores para identificar una (o más) buenas soluciones, y luego clonándolas y aplicando una mutación de alta tasa (mutación masiva) para producir un número de individuos en las proximidades del punto de partida."]},{"cell_type":"markdown","metadata":{"id":"9KHLjKOVR9ff","colab_type":"text"},"source":["## Hibridación en la variación: cruce y mutación 'inteligentes'\n","Como su nombre indica, consiste en introducir sesgos en el proceso de mutación y cruce, introduciendo de esta forma información específica del problema.\n","\n","Un ejemplo de este tipo de hibridación sería el siguiente: supongamos que estamos usando un algoritmo genético para evolucionar distintas selecciones de las características (_features_) que se emplearán para entrenar un clasificador. Podríamos 'influenciar' la mutación para obtener selecciones de _features_ más compactas, aumentando la probabilidad de que se pase de un valor de \"usar\" a otro de \"no usar\" con respecto a la operación contraria.\n","\n","Se han desarrollado multitud de operadores de mutación y cruce específicos para algunos de los problemas clásicos de optimización que hemos visto durante este curso."]},{"cell_type":"markdown","metadata":{"id":"Z5qXVUrnUzw5","colab_type":"text"},"source":["## Búsqueda local después de la variación\n","El uso más común de la hibridación dentro de los AEs, y el que mejor se ajusta al concepto de Dawkins del meme, es a través de la aplicación de una o más fases de mejora local a cada uno de los miembros individuales de la población durante el ciclo evolutivo, es decir, la búsqueda local actúa sobre soluciones completas creadas por mutación o recombinación. Esto puede ocurrir en diferentes lugares del ciclo, es decir, antes o después de la selección o después del cruce y/o la mutación. \n","\n","Por ejemplo, podríamos aplicar un descenso de gradiente a cada uno de los miembros de la población resultante de aplicar cruce y mutación. De esta forma no solo estamos añadiendo diversidad en la población, sino que estamos aplicando una pequeña mejora a cada una de las soluciones candidatas.\n"]},{"cell_type":"markdown","metadata":{"id":"6pC4vZjgdQ-X","colab_type":"text"},"source":["## Pseudo-código de un algoritmo memético\n","\n","\n","```\n","1. Inicializar población <- Hibridación\n","2. Evaluar los candidatos de la población\n","3. Mientras no se cumpla la condición de parada\n","    3.1. Seleccionar padres\n","    3.2. Recombinación (cruce) <- Hibridación\n","    3.3. Mutación <- Hibridación\n","    3.4. Búsqueda local de cada candidato\n","    3.5. Evaluación de nuevos candidatos\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"1FkmVSdMeX3y","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}